{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911db5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target feature for training data\n",
    "y_train = train_df[\"target\"]\n",
    "X_train = train_df.drop(columns = [\"target\"])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaeb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target feature for testing data\n",
    "y_test = test_df[\"target\"]\n",
    "X_test = test_df.drop(columns = [\"target\"])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding dataframes\n",
    "X_dummies_train = pd.get_dummies(X_train)\n",
    "X_dummies_test = pd.get_dummies(X_test)\n",
    "print(f\"Train: {X_dummies_train.shape}, Test: {X_dummies_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb650c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert output labels to 0 and 1\n",
    "y_label_train = LabelEncoder().fit_transform(train_df['target'])\n",
    "y_label_train\n",
    "\n",
    "y_label_test = LabelEncoder().fit_transform(test_df['target'])\n",
    "y_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30919c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "for col in X_dummies_train.columns:\n",
    "    if col not in X_dummies_test.columns:\n",
    "        X_dummies_test[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train: {X_dummies_train.shape}, Test: {X_dummies_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913816d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_logistic  = LogisticRegression(solver='lbfgs').fit(X_dummies_train, y_label_train) \n",
    "\n",
    "print(f\"Training Data Score: {clf_logistic.score(X_dummies_train, y_label_train)}\")\n",
    "print(f\"Testing Data Score: {clf_logistic.score(X_dummies_test, y_label_test)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054103f4",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model - Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2260f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_forest = RandomForestClassifier(random_state=42, n_estimators=200).fit(X_dummies_train, y_label_train)\n",
    "\n",
    "print(f'Training Score: {clf_forest.score(X_dummies_train, y_label_train)}')\n",
    "print(f'Testing Score: {clf_forest.score(X_dummies_test, y_label_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d13a9",
   "metadata": {},
   "source": [
    "### Results - Unscaled\n",
    "LR Unscaled: Training Data Score: 0.6516420361247948, Testing Data Score: 0.5091450446618461\n",
    "\n",
    "RF Unscaled: Training Score: 1.0, Testing Score: 0.6482347937048064\n",
    "\n",
    "On unscaled data, the Random Forest Classifier performed better with a score of .64. However there is an overfitting problem on the training dataset, showing that complexity may need to be reduced for Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da00500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using StandardScaler()\n",
    "scaler = StandardScaler().fit(X_dummies_train)\n",
    "X_train_scaled = scaler.transform(X_dummies_train)\n",
    "X_test_scaled = scaler.transform(X_dummies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64462485",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction - Scaled\n",
    "Prediction: The score for Logistic Regression will improve due to scaling whereas the score for Random Forest will \n",
    "remain the same. Graphical-model classifiers like Random Forest are invariant to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression Model - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "clf_lr = LogisticRegression().fit(X_train_scaled, y_label_train)\n",
    "\n",
    "print(f'Testing Score: {clf_lr.score(X_test_scaled, y_label_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "y_true = y_label_test\n",
    "y_pred = clf_lr.predict(X_test_scaled)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d81e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Low Risk', 'High Risk']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=0)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Logistic Regression Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7de7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Confusion Matrix shows that the Logistic Regression classifier struggled a bit more at predicting\n",
    "the Low Risk label, but overall predicted both labels quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e276f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "target_names = ['low risk', 'high risk']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "The classification report shows that precision is high, meaning that the model was careful to avoid labeling things “low risk” that aren’t low risk. On the other hand, recall is a bit lower for low risk, which means that the classifier is missing some 'low risks' because it is being too careful. Because precision and recall are both high, F1 is also high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e66d38",
   "metadata": {},
   "source": [
    "### Random Forewr Model - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf_rf = RandomForestClassifier(random_state=42, n_estimators=500).fit(X_train_scaled, y_label_train)\n",
    "\n",
    "print(f'Testing Score: {clf_rf.score(X_test_scaled, y_label_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3193fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for RF model\n",
    "y_true1 = y_label_test\n",
    "y_pred1 = clf_rf.predict(X_test_scaled)\n",
    "confusion_matrix(y_true1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89054032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_true1, y_pred1)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Blues, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Low Risk', 'High Risk']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=0)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab738276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classification Report for Random Forest model\n",
    "print(classification_report(y_true1, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad0f27",
   "metadata": {},
   "source": [
    "The classification report shows that precision is high for high risk, meaning that the model was careful to avoid labeling things “high risk” that aren’t low risk. On the other hand, recall is low for high risk, which means that the classifier is missing some 'high risks' because it is being too careful. The F1-score reflects the imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa0088",
   "metadata": {},
   "source": [
    "### Results - Scaled\n",
    "LR Scaled: Testing Score: 0.7598894087622289\n",
    "\n",
    "RF Scaled: Testing Score: 0.6456826882177796\n",
    "\n",
    "Overall, scaling greatly improved the score of the Logistic Regression model from .50 to .75 so that it outperformed the Random Forest model. This shows that sometimes a simple model with scaled data can be a better fit than one with more complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
